# Production-Grade RAG Chatbot

A production-ready Retrieval-Augmented Generation (RAG) chatbot built with Python, **LangChain**, ChromaDB, and MCP support.

## Features

- **LangChain Integration**: Full LangChain orchestration for LLMs, embeddings, document loaders, and chains
- **Multiple LLM Providers**: OpenAI, Ollama support
- **Multiple Embedding Providers**: OpenAI, HuggingFace, Ollama
- **Vector Storage**: ChromaDB for efficient semantic search
- **Document Support**: PDF, TXT, Markdown ingestion
- **MCP Support**: Model Context Protocol for tool integration
- **Production Ready**: Docker, logging, health checks, structured configuration
- **Testing**: pytest + Hypothesis for unit and property-based tests

## Project Status

### âœ… Completed (Phase 1 & 2.1-2.2)

- [x] Project structure and configuration
- [x] Pydantic Settings with validation
- [x] Structured logging with correlation IDs
- [x] LLM Factory (OpenAI, Ollama)
- [x] Embeddings Factory (OpenAI, HuggingFace, Ollama)
- [x] Comprehensive test suite with pytest + Hypothesis

### ðŸš§ In Progress (Phase 2.3)

- [ ] Vector Store Manager (ChromaDB)
- [ ] Connection management and health checks
- [ ] Document operations (add/search/delete)

### ðŸ“‹ Planned

- Phase 3: Document Ingestion Pipeline
- Phase 4: Retrieval System
- Phase 5: Chat System with Memory
- Phase 6: MCP Server
- Phase 7: REST API
- Phase 8: Docker Configuration
- Phase 9: Error Handling
- Phase 10: Integration Tests

## Technology Stack

| Category | Technology |
|----------|------------|
| **Framework** | LangChain, LangGraph |
| **LLM** | OpenAI GPT-4, Ollama |
| **Embeddings** | OpenAI ada-002, HuggingFace, Ollama |
| **Vector Store** | ChromaDB |
| **API** | FastAPI |
| **Testing** | pytest, Hypothesis |
| **Code Quality** | Black, Ruff, MyPy |
| **Logging** | structlog |
| **Containerization** | Docker, Docker Compose |

## Quick Start

### Prerequisites

```bash
# Python 3.11+
python --version

# Optional: Ollama for local LLMs
# brew install ollama
```

### Installation

```bash
# Clone repository
cd rag-chatbot

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -e ".[dev]"

# Copy environment template
cp .env.example .env
# Edit .env and add your OPENAI_API_KEY
```

### Run Tests

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=src --cov-report=html

# Run property-based tests only
pytest -m property

# Run with Hypothesis debug profile
HYPOTHESIS_PROFILE=debug pytest
```

### Pre-commit Hooks

```bash
# Install pre-commit hooks
pre-commit install

# Run manually
pre-commit run --all-files
```

## Project Structure

```
rag-chatbot/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config/settings.py      # Pydantic settings with validation
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ llm.py               # âœ… LLM factory (OpenAI, Ollama)
â”‚   â”‚   â”œâ”€â”€ embeddings.py        # âœ… Embeddings factory
â”‚   â”‚   â””â”€â”€ vectorstore.py       # ðŸš§ ChromaDB manager
â”‚   â”œâ”€â”€ ingestion/               # ðŸ“‹ Document loaders & chunking
â”‚   â”œâ”€â”€ retrieval/               # ðŸ“‹ RAG retriever & reranker
â”‚   â”œâ”€â”€ chat/                    # ðŸ“‹ Conversation chain & memory
â”‚   â”œâ”€â”€ mcp/                     # ðŸ“‹ MCP server & tools
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ middleware.py        # âœ… Correlation ID middleware
â”‚   â”‚   â”œâ”€â”€ routes.py            # ðŸ“‹ FastAPI endpoints
â”‚   â”‚   â””â”€â”€ models.py            # ðŸ“‹ Pydantic models
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ logging.py           # âœ… Structured logging
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ conftest.py              # âœ… Shared fixtures
â”‚   â”œâ”€â”€ unit/                    # âœ… Unit tests
â”‚   â”œâ”€â”€ integration/             # ðŸ“‹ Integration tests
â”‚   â””â”€â”€ property/                # ðŸ“‹ Property-based tests
â”œâ”€â”€ docker/                      # ðŸ“‹ Dockerfiles & compose
â”œâ”€â”€ documents/                   # Document ingestion directory
â”œâ”€â”€ pyproject.toml               # âœ… Project configuration
â””â”€â”€ .env.example                 # âœ… Environment template
```

## Configuration

All configuration is managed through environment variables. See `.env.example` for complete reference.

### Key Settings

```bash
# LLM Configuration
OPENAI_API_KEY=sk-your-key
LLM_MODEL=gpt-4
LLM_PROVIDER=openai

# Embedding Configuration
EMBEDDING_MODEL=text-embedding-ada-002
EMBEDDING_PROVIDER=openai

# ChromaDB Configuration
CHROMA_HOST=localhost
CHROMA_PORT=8000
CHROMA_COLLECTION=documents

# Application Configuration
LOG_LEVEL=INFO
DEBUG=false
```

## Testing Strategy

### Unit Tests (pytest)
- Fast, isolated tests with mocks
- Test business logic and edge cases
- Located in `tests/unit/`

### Property-Based Tests (Hypothesis)
- Generate random test inputs
- Test invariants and properties
- Catch edge cases automatically

### Integration Tests
- Test with real services (ChromaDB, etc.)
- Use testcontainers for isolation
- Located in `tests/integration/`

## Development

### Code Quality

```bash
# Format code
black src/ tests/

# Lint code
ruff check src/ tests/

# Type check
mypy src/

# Run all quality checks
pre-commit run --all-files
```

### Adding New Features

1. Update requirements in `pyproject.toml`
2. Implement feature with type hints and docstrings
3. Write unit tests (pytest)
4. Write property tests (Hypothesis) for data transformations
5. Update configuration in `settings.py` if needed
6. Run quality checks

## Documentation

- **Requirements**: `.specflow/specs/active/rag-chatbot/requirements.md`
- **Design**: `.specflow/specs/active/rag-chatbot/design.md`
- **Tasks**: `.specflow/specs/active/rag-chatbot/tasks.md`
- **Project Context**: `.specflow/project.md`

## License

MIT

## Contributing

1. Follow PEP 8 and project conventions
2. Write tests for all new code
3. Ensure all tests pass
4. Run pre-commit hooks
5. Update documentation
